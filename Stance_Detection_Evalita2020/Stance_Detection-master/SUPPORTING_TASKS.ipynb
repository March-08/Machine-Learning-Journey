{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SUPPORTING_TASKS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccFb7Ogal5xs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c78dcaec-f2fc-4394-f6d4-d9dea0f71402"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 3.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 22.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 49.2MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ayWPKG4WbvM"
      },
      "source": [
        "# DATASET DOWNLOAD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu8RmiG4kiuy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "2bf249b0-ff3c-4370-e084-bc2e38e88700"
      },
      "source": [
        "#SENTIPOLC DATASET\n",
        "!gdown --id 1OjAR47V-rVYwaSFtu-OWCbxpRhfhORv7\n",
        "!gdown --id 1iD_MhCqoqUPeg8f3I3QN0PF_FJPTkCFT\n",
        "\n",
        "#HATE SPEECH DATASET\n",
        "!gdown --id 16fiKO4XSjlYz0zt9AMiW5h-Kbb2tyJ9w\n",
        "\n",
        "#IRONY DETECTION DATASET\n",
        "!gdown --id 1tQIofTUHkflMjhky5UKwc7FaYucTClCT\n",
        "!gdown --id 10bTHDmrn_-_u3_P6jLIjZqkbNkQOr9vk\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1FZ4teXVlw1PBQsM3e6Fxaz-cSDU82a6w\n",
            "To: /content/training_set_sentipolc16.csv\n",
            "100% 1.03M/1.03M [00:00<00:00, 69.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QHCgrXE-Ys3eOGub4RdenvpRcE77t7gj\n",
            "To: /content/test_set_sentipolc16_gold2000.csv\n",
            "100% 329k/329k [00:00<00:00, 119MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14iWpHn47t5h9-67ruC5TWmAVXchjTOQh\n",
            "To: /content/haspeede_TW-train.tsv\n",
            "100% 391k/391k [00:00<00:00, 52.2MB/s]\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHK8d_CqWhYU"
      },
      "source": [
        "# IMPORT SECTION\n",
        "Here are defined all the libraries used and the path of the drive that contains the tagged datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEcyRqm_ltF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9ee1eee3-5e64-4dc2-d25e-ea895470de03"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup, AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, random_split, TensorDataset\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MODEL_PATH = F\"/content/gdrive/My Drive/Models/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npAce6YwW4qO"
      },
      "source": [
        "# SELECTION OF TASK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3keGfB_3mEmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "135b804b-7aec-4c47-be6e-d86ce538ea3a"
      },
      "source": [
        "#CHOOSE ONE OF THE THREE SUPPORTING TASKS --- HATE, SENTIMENT, IRONY\n",
        "SUPPORTING_TASK = \"HATE\"\n",
        "\n",
        "if SUPPORTING_TASK = \"HATE\":\n",
        "  df = pd.read_csv(\"haspeede_TW-train.tsv\", sep=\"\\t\", names= ['id','tweet','label'])\n",
        "  MODEL_PATH =  F\"/content/gdrive/My Drive/hatespeech_best\"\n",
        "\n",
        "elif SUPPORTING_TASK = \"SENTIMENT\":\n",
        "  df = pd.read_csv(\"training_set_sentipolc16.csv\")\n",
        "  df_test = pd.read_csv(\"test_set_sentipolc16_gold2000.csv\", error_bad_lines=False, encoding='latin', names=df.columns)\n",
        "  MODEL_PATH = F\"/content/gdrive/My Drive/Models/sentipolc_best\"\n",
        "  \n",
        "elif SUPPORTING_TASK = \"IRONY\":\n",
        "  df = pd.read_csv(\"training_ironita2018.csv\", sep=\"\\t\")\n",
        "  df_test = pd.read_csv(\"test_gold_ironita2018.csv\", sep=\"\\t\")\n",
        "  MODEL_PATH = F\"/content/gdrive/My Drive/Models/irony_best\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6847</td>\n",
              "      <td>@matteorenzi ...all'invasione di questi animal...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2066</td>\n",
              "      <td>È terrorismo anche questo, per mettere in uno ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2045</td>\n",
              "      <td>@Nanoalto @FedeAngeli infatti finché ci hanno ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6630</td>\n",
              "      <td>@dinofarnesi Piovegovernolad    In  Italia   a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5556</td>\n",
              "      <td>#londonattack chiedete ai buonisti del cavolo ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                              tweet  label\n",
              "0  6847  @matteorenzi ...all'invasione di questi animal...      1\n",
              "1  2066  È terrorismo anche questo, per mettere in uno ...      0\n",
              "2  2045  @Nanoalto @FedeAngeli infatti finché ci hanno ...      0\n",
              "3  6630  @dinofarnesi Piovegovernolad    In  Italia   a...      1\n",
              "4  5556  #londonattack chiedete ai buonisti del cavolo ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik8nK0-eXmN5"
      },
      "source": [
        "# SETTING PRE TRAINED MODEL AND TOKENIZER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wFno9JFmlNT"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'Musixmatch/umberto-commoncrawl-cased-v1'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6gd9z5hrBFN"
      },
      "source": [
        "#SET MAXIMUM NUMBER OF TOKENS PER SENTENCE\n",
        "MAX_LEN = 70"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLHX783bYZzX"
      },
      "source": [
        "# DATASET CLASS\n",
        "Now we create the class that contains the information of each tweet and then we use it to create the data structure containing the tokenized phrases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPL27jW4rErS"
      },
      "source": [
        "class TaskDataset(Dataset):\n",
        "  def __init__(self, tweet_id, label, tweet, tokenizer, max_len):\n",
        "    self.tweet_id = tweet_id\n",
        "    self.label = label\n",
        "    self.tweet = tweet\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  def __len__(self):\n",
        "    return len(self.tweet)\n",
        "  def __getitem__(self, item):\n",
        "    tweet = str(self.tweet[item])\n",
        "    tweet_id = int(self.tweet_id[item])\n",
        "    label = self.label[item]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      padding='max_length',\n",
        "      return_attention_mask=True,\n",
        "      truncation=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "    return {\n",
        "      'tweet_id': torch.tensor(tweet_id, dtype=torch.int),\n",
        "      'tweet' : tweet,\n",
        "      'label': torch.tensor(label, dtype=torch.long),\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWRXUqeErNTy"
      },
      "source": [
        "if SUPPORTING_TASK = \"HATE\":\n",
        "  df_train, df_val = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_SEED\n",
        "  )\n",
        "else:\n",
        "  df_train = df\n",
        "  df_val = df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyyYhL-1rZXa"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = TaskDataset(\n",
        "    tweet=df.tweet.to_numpy(),\n",
        "    label=df.label.to_numpy(),\n",
        "    tweet_id=df.id.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viz9qP7frekf"
      },
      "source": [
        "#DEFINE NUMBER OF BATCH\n",
        "BATCH_SIZE = 32\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdvXbxTgY_Ef"
      },
      "source": [
        "# TASK CLASSIFIER\n",
        "This class is used to load the UmBERTo model and apply activation functions that will be used in the training process.\n",
        "Furthermore, to make the training phase more consistent with the test phase, we also used a dropout function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOyAJqDYsXIG"
      },
      "source": [
        "class TaskClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(HateClassifier, self).__init__()\n",
        "    self.bert = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)\n",
        "\n",
        "  def save_pretrained(self, path):\n",
        "    self.bert.save_pretrained(path)\n",
        "    torch.save(self.out,path + \"_out_layer\" )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syCid1pQsi8R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf4537ad-616d-405e-c7c0-583657b90654"
      },
      "source": [
        "if SUPPORTING_TASK = \"SENTIMENT\":\n",
        "  model = None\n",
        "  model = HateClassifier(3)\n",
        "  model = model.to(device)\n",
        "else:\n",
        "  model = None\n",
        "  model = HateClassifier(2)\n",
        "  model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUJWlzHYZWf7"
      },
      "source": [
        "# SETTING OF HYPER PARAMETERS\n",
        "In the following code we have just set some hyperparameters, as the number of epochs or the optimizer, you should able to change these easily"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMD7w14VtBg9"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = int((len(train_data_loader) * EPOCHS)) \n",
        "warmup_step = int(len(train_data_loader))  \n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=warmup_step,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VlttXXSZd8f"
      },
      "source": [
        "# MODEL TRAINING\n",
        "Here it is an helper function for training our model for one epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-aYOMGPtTRP"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
        "\n",
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  all_predictions , true_labels = [], []\n",
        "\n",
        "\n",
        "  correct_predictions = 0\n",
        "  losses = []\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    label = d[\"label\"].to(device)\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, label)\n",
        "\n",
        "    all_predictions.append(preds.cpu().data)\n",
        "    true_labels.append(label.cpu().data) \n",
        "\n",
        "    correct_predictions += torch.sum(preds == label)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "  true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "  #SYSTEM MEASURES\n",
        "  f1 = f1_score(true_labels, all_predictions, average=\"macro\")\n",
        "  precision = precision_score(true_labels, all_predictions, average=\"macro\")\n",
        "  recall = recall_score(true_labels, all_predictions, average=\"macro\")\n",
        "\n",
        "    \n",
        "  return correct_predictions.double() / n_examples, np.mean(losses), precision , recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnwr0JpAZg6G"
      },
      "source": [
        "# MODEL EVALUATION\n",
        "This function helps us to avaluate our model given a data loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7wO42GgtdA0"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  \n",
        "  predictions = []\n",
        "  all_predictions , true_labels = [], []\n",
        "\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      label = d[\"label\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      loss = loss_fn(outputs, label)\n",
        "      losses.append(loss.item())\n",
        "      correct_predictions += torch.sum(preds == label)\n",
        "      predictions.append({\"tweet_id\": d[\"tweet_id\"], \"label\": preds, \"exact\": label})\n",
        "\n",
        "      all_predictions.append(preds.cpu().data)\n",
        "      true_labels.append(label.cpu().data) \n",
        "  \n",
        "    \n",
        "  all_predictions = np.concatenate(all_predictions, axis=0)\n",
        "  true_labels = np.concatenate(true_labels, axis=0)\n",
        "  \n",
        "  #SYSTEM MEASURES\n",
        "  f1 = f1_score(true_labels, all_predictions, average=\"macro\")\n",
        "  precision = precision_score(true_labels, all_predictions, average=\"macro\")\n",
        "  recall = recall_score(true_labels, all_predictions, average=\"macro\")\n",
        " \n",
        "  return correct_predictions.double() / n_examples, np.mean(losses), predictions, precision , recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcLQQc76Zlu5"
      },
      "source": [
        "# RUNNING SECTION AND SAVING OF MODEL\n",
        "In the following code we run the models, and save the one that returns the best accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1nnuUL2trhA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "a74fa5d1-36d5-4d04-9a2b-abe9d438d4ff"
      },
      "source": [
        "history = defaultdict(list)\n",
        "\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "  train_acc, train_loss, p, r, f1 = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc} precision {p} recall {r} f1 {f1}')\n",
        "  val_acc, val_loss,predictions, p,r,f1 = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc} precision {p} f1 {f1} ')\n",
        "\n",
        "  print()\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "  if val_acc > best_accuracy:\n",
        "    model.save_pretrained(MODEL_PATH)\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.580657813946406 accuracy 0.6970833333333334 precision 0.6372200871585725 recall 0.5793292924896633 f1 0.5758780391700258\n",
            "Val   loss 0.6103149056434631 accuracy 0.6533333333333333 precision 0.5771812080536913 f1 0.4041708043694141 \n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.4985181001822154 accuracy 0.7591666666666668 precision 0.7230388679209587 recall 0.7263757856603388 f1 0.7246253101736972\n",
            "Val   loss 0.6575407385826111 accuracy 0.7733333333333334 precision 0.8216364258815474 f1 0.6977777777777778 \n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.4061372861266136 accuracy 0.8295833333333333 precision 0.8032232126501997 recall 0.8059322956003021 f1 0.8045446553536465\n",
            "Val   loss 0.44912097720723404 accuracy 0.8333333333333334 precision 0.8390018053695183 f1 0.8022125819169557 \n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.2844910051425298 accuracy 0.89375 precision 0.877154593343055 recall 0.8784626659327437 f1 0.877803115661148\n",
            "Val   loss 0.41392031233561666 accuracy 0.8383333333333334 precision 0.824406457739791 f1 0.8187994059609391 \n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.2100695795814196 accuracy 0.9308333333333334 precision 0.9189477426235335 recall 0.9224068408453769 f1 0.9206437734045096\n",
            "Val   loss 0.40251973585078593 accuracy 0.8483333333333334 precision 0.8306666666666667 f1 0.835597134692919 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}